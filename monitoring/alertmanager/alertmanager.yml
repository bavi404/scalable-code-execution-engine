# =============================================================================
# Alertmanager Configuration
# =============================================================================

global:
  # Default SMTP settings
  smtp_smarthost: 'smtp.example.com:587'
  smtp_from: 'alertmanager@code-execution.example.com'
  smtp_auth_username: 'alertmanager'
  smtp_auth_password_file: '/etc/alertmanager/smtp_password'
  smtp_require_tls: true
  
  # Slack settings
  slack_api_url_file: '/etc/alertmanager/slack_webhook'
  
  # PagerDuty settings
  pagerduty_url: 'https://events.pagerduty.com/v2/enqueue'

# Templates
templates:
  - '/etc/alertmanager/templates/*.tmpl'

# Route tree
route:
  # Default receiver
  receiver: 'platform-team-slack'
  
  # Group alerts
  group_by: ['alertname', 'cluster', 'pool']
  group_wait: 30s
  group_interval: 5m
  repeat_interval: 4h
  
  # Child routes
  routes:
    # Critical alerts go to PagerDuty
    - match:
        severity: critical
      receiver: 'pagerduty-critical'
      group_wait: 10s
      repeat_interval: 1h
      continue: true
    
    # Critical alerts also go to Slack
    - match:
        severity: critical
      receiver: 'platform-team-slack-critical'
      continue: true
    
    # Warning alerts
    - match:
        severity: warning
      receiver: 'platform-team-slack'
      continue: true
    
    # Security alerts (eBPF violations)
    - match:
        alertname: SyscallViolationDetected
      receiver: 'security-team-pagerduty'
      group_wait: 0s
      repeat_interval: 10m
    
    # Queue alerts
    - match_re:
        alertname: '.*Queue.*'
      receiver: 'platform-team-slack'
      group_by: ['alertname', 'pool']
    
    # Worker alerts
    - match_re:
        alertname: '.*Worker.*'
      receiver: 'platform-team-slack'
      group_by: ['alertname', 'pool', 'worker']
    
    # Infrastructure alerts
    - match:
        team: infrastructure
      receiver: 'infrastructure-team'

# Inhibition rules
inhibit_rules:
  # If critical queue alert is firing, silence warnings
  - source_match:
      alertname: 'CriticalQueueDepth'
    target_match:
      alertname: 'HighQueueDepth'
    equal: ['pool']
  
  # If no workers available, silence low worker count
  - source_match:
      alertname: 'NoWorkersAvailable'
    target_match:
      alertname: 'LowWorkerCount'
    equal: ['pool']
  
  # If critical error rate, silence warning
  - source_match:
      alertname: 'CriticalErrorRate'
    target_match:
      alertname: 'HighErrorRate'
    equal: ['cluster']

# Receivers
receivers:
  # Slack channels
  - name: 'platform-team-slack'
    slack_configs:
      - channel: '#code-execution-alerts'
        send_resolved: true
        title: '{{ template "slack.title" . }}'
        text: '{{ template "slack.text" . }}'
        actions:
          - type: button
            text: 'Runbook :book:'
            url: '{{ (index .Alerts 0).Annotations.runbook_url }}'
          - type: button
            text: 'Dashboard :chart_with_upwards_trend:'
            url: 'https://grafana.example.com/d/code-execution-overview'
  
  - name: 'platform-team-slack-critical'
    slack_configs:
      - channel: '#code-execution-critical'
        send_resolved: true
        title: ':rotating_light: {{ template "slack.title" . }}'
        text: '{{ template "slack.text" . }}'
        color: '{{ if eq .Status "firing" }}danger{{ else }}good{{ end }}'
  
  # PagerDuty
  - name: 'pagerduty-critical'
    pagerduty_configs:
      - service_key_file: '/etc/alertmanager/pagerduty_service_key'
        severity: '{{ if .Labels.severity }}{{ .Labels.severity }}{{ else }}critical{{ end }}'
        description: '{{ template "pagerduty.description" . }}'
        details:
          firing: '{{ template "pagerduty.firing" . }}'
          num_firing: '{{ .Alerts.Firing | len }}'
          num_resolved: '{{ .Alerts.Resolved | len }}'
  
  - name: 'security-team-pagerduty'
    pagerduty_configs:
      - service_key_file: '/etc/alertmanager/pagerduty_security_key'
        severity: critical
        description: 'Security Alert: {{ .GroupLabels.alertname }}'
  
  # Email
  - name: 'infrastructure-team'
    email_configs:
      - to: 'infra-team@example.com'
        send_resolved: true
        headers:
          Subject: '[{{ .Status | toUpper }}] Code Execution Alert: {{ .GroupLabels.alertname }}'

